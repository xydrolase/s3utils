#!/usr/bin/env python

from __future__ import print_function

from argparse import ArgumentParser
from copy import copy

import sys
import os
import time

import boto

import s3util.io

OVERWRITE = dict(zip(['skip', 'replace', 'suffix', 'versioning'], range(4)))

class DirPolicy:
    def __init__(self, bucket='', root='', prefix='', use_relpath=True, 
            flatten=False, overwrite='overwrite', **kwargs):
        self.bucket = bucket
        self.root = root
        self.prefix = prefix
        self.use_relpath = use_relpath
        self.flatten = flatten
        self.overwrite = overwrite

        # if root is empty, it implies that this policy applies to the current
        # working directory.
        self.is_cwd = not bool(root)

        self.absroot = os.path.abspath(root)

    def __contains__(self, fname):
        return os.path.abspath(fname).startswith(self.absroot)

    def __lt__(self, rhs):
        return self.is_cwd < rhs.is_cwd or \
            len(self.absroot) > len(rhs.absroot)

    def __cmp__(self, rhs):
        """Sort, in descending order, the depth of path (level of folders).

        Current working directory has the lowest priority.
        """
        return cmp(self.is_cwd, rhs.is_cwd) or \
            -cmp(len(self.absroot), len(rhs.absroot))

    def __repr__(self):
        return "<DirPolicy '{0}'>".format(self.absroot)

    def s3_key(self, fname):
        abspath = os.path.abspath(fname)
        relpath = os.path.relpath(abspath, self.absroot)

        s3_path = relpath if self.use_relpath else fname
        if self.flatten:
            s3_path = os.path.basename(s3_path)
        s3_key = os.path.join(self.prefix, s3_path)

        return {
                'abspath': abspath, 
                'relpath': relpath,
                'bucket': self.bucket,
                'overwrite': self.overwrite,
                'key': s3_key
                }

def parse_args(argv=None):
    parser = ArgumentParser(
            description="Amazon S3 Utilities.")
    parser.add_argument("-c", "--config", default="~/.s3util/config.yaml",
            help="Specify the configuration file.")

    sub_parsers = parser.add_subparsers(
            title="available commands", 
            metavar="{command}")

    sp_put = sub_parsers.add_parser("put", 
            help="Upload a local file to a S3 bucket.")

    sp_put.add_argument(
        "-b", "--bucket", 
        help="Bucket to which the file is uploaded.")
    sp_put.add_argument(
        "-p", "--prefix", default='',
        help="Directory (in the bucket) to which the file is uploaded.")
    sp_put.add_argument(
        "-o", "--overwrite", 
        choices=["skip", "replace", "suffix", "versioning"],
        default="replace",
        help="How to deal with existing file(s).")
    sp_put.add_argument(
        "-A", "--abspath", default=False, action="store_true",
        help="Use absolute path of local file to construct S3 file key.")
    sp_put.add_argument(
        "--flatten", action="store_true", default=False,
        help="Discard the subdirectory structures for local files.")
    sp_put.add_argument(
        "files", nargs="+", metavar="file",
        help="File(s) to be uploaded to S3.")

    sp_put.set_defaults(action=cmd_put)

    sp_config = sub_parsers.add_parser("config",
            help="Configure s3util.")

    if (argv is None and len(sys.argv) == 1) \
            or (type(argv) in (list, tuple) and len(argv) == 0):
        parser.print_help()
        parser.exit()

    args = parser.parse_args(argv)

    if hasattr(args, 'overwrite'):
        args.overwrite = OVERWRITE.get(args.overwrite, 1)

    args.use_relpath = not args.abspath

    return args

def load_config_file(conf_file):
    import yaml

    if conf_file.find('~') != -1:
        conf_file = os.path.expanduser(conf_file)

    if not os.path.exists(conf_file):
        print("fatal: configuration file {0} does not exist.".format(
            conf_file), file=sys.stderr)

        sys.exit(1)

    st_mode = os.stat(conf_file).st_mode
    # check if any of the lower 7 bits are set. if so, warn the user and abort
    if st_mode & 0x7f:
        print(("warning: you should set the mode of {0} to "
            "0600 or 0400 to protect your credentials.").format(conf_file), 
            file=sys.stderr)
        sys.exit(1)

    with open(conf_file) as f:
        try:
            conf = yaml.load(f)
        except yaml.scanner.ScannerError as e:
            err_msg = ("fatal: corrupted configuration file {0}.\n\n"
                    "{1}").format(conf_file, e)

            print(err_msg, file=sys.stderr)
            sys.exit(1)

        conf.setdefault('directories', [])
        return conf

def generate_s3_key(files, conf):
    if type(files) is str:
        files = [files]

    dir_policies = [DirPolicy(root='', **conf['default'])]
    for d in conf['directories']:
        if 'root' in d:
            pol = copy(conf['default'])
            pol.update(d)

            dir_policies.append(DirPolicy(**pol))


    for f in files:
        # choose the most pertinent/narrow policy, if multiple policies are
        # associated with the file.
        # the 'default' policy should always apply
        policy = sorted([dirp for dirp in dir_policies if f in dirp])[0]

        yield policy.s3_key(f)

def cmd_put(args):
    conf = load_config_file(args.config)

    # overwrite default settings with arguments specified by the user.
    conf['default'].update(dict(
        (attr, getattr(args, attr))
        for attr in ['overwrite', 'prefix', 'bucket', 'flatten', 'use_relpath']
        if hasattr(args, attr) and getattr(args, attr)))

    if not 'aws_credentials' in conf:
        raise ValueError(
                "Invalid configuration file: `aws_credentials` missing.")

    if conf['aws_credentials'].get('use_iam_role', False):
        conn = s3util.io.Connection(
            access_key_id=None,
            secret_access_key=None)
    else:
        creds = conf['aws_credentials']
        try:
            conn = s3util.io.Connection(
                    access_key_id=creds.get('access_key_id', None),
                    secret_access_key=creds.get('secret_access_key', None))
        except boto.exception.NoAuthHandlerFound:
            err_msg = ("fatal: You have not set up your credentials for "
                    " authentication.\n\n"
                    "Please set up the credentials via command: \n"
                    "   s3util config credentials")

            print(err_msg, file=sys.stderr)

            sys.exit(1)

    if not args.bucket:
        def_conf = conf.get('default', {})
        args.bucket = def_conf.get('bucket', None)

        if args.bucket is None:
            print("fatal: bucket id is missing.", file=sys.stderr)
            sys.exit(1)

    for f in generate_s3_key(args.files, conf):
        conn.put(**f)

    conn = None

def main():
    args = parse_args()

    if args.action:
        args.action(args)

if __name__ == "__main__":
    main()
